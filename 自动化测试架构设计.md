这是一个**非常成熟、工程化程度很高**的需求，本质上你不是在“写测试”，而是在做一个 **自动化测试平台 / 测试编排系统（Test Orchestration System）**。

我会从 **架构设计 → 技术选型 → 关键模块 → 数据模型 → 可视化与前端 → 实施路线** 六个层面给你一套**可长期演进**的建议，**完全贴合你：FastAPI + uv + 多用户并发 + Agent 测试**这个背景。

---

# 一、先给你一个整体定位（非常重要）

> 这个新项目的定位不是 pytest runner
> 而是一个 **Agent 自动化测试 & 压测 & 行为回归平台**

你要解决的不是：

* “某个接口是否 200”

而是：

* 多用户并发下
* 多轮 Agent 对话
* 多阶段节点（LLM → Tool → Memory → RAG → Response）
* 是否**按预期行为执行**
* 是否**在时间 / token / 成功率**阈值内

---

# 二、推荐总体架构（你可以直接照这个来）

```
┌─────────────┐
│   Frontend  │  实时进度 / DAG / 报表
└─────▲───────┘
      │ WebSocket / SSE
┌─────┴───────┐
│ Test API    │ FastAPI + uv
│ (Control)   │
└─────▲───────┘
      │ async / queue
┌─────┴──────────────┐
│ Test Orchestrator  │  核心
│  - 场景调度        │
│  - 并发控制        │
│  - 状态机          │
└─────▲──────────────┘
      │
┌─────┴──────────────┐
│ Test Workers       │ 多协程 / 多进程
│  - 模拟用户        │
│  - 执行 Agent 流程 │
└─────▲──────────────┘
      │ HTTP / SDK
┌─────┴──────────────┐
│  Agent Project     │ 你现有的项目
└────────────────────┘
```

---

# 三、技术选型建议（非常关键）

## 1️⃣ 项目基础

| 组件     | 推荐                      |
| ------ | ----------------------- |
| Web 框架 | **FastAPI**             |
| 包管理    | **uv**                  |
| Python | 3.11 / 3.12             |
| 并发     | asyncio + anyio         |
| 状态存储   | PostgreSQL / SQLite（起步） |
| 临时状态   | Redis（可选）               |

---

## 2️⃣ 测试执行层（不要用 pytest）

❌ **不推荐 pytest / locust**

你需要的是：

> **可编排、可回放、可追踪的“测试行为流”**

### 推荐抽象：Scenario / Step / User

```python
Scenario
 ├── UserProfile (模拟用户)
 ├── Steps
 │    ├── SendMessage
 │    ├── Wait
 │    ├── CallTool
 │    ├── Assert
 └── Metrics
```

---

## 3️⃣ 测试配置（必须是声明式）

### YAML / JSON 驱动（强烈推荐）

```yaml
scenario: qa_agent_basic
users: 50
ramp_up: 10s

user_profile:
  memory: enabled
  kb: test_kb
  model: gpt-4.1

steps:
  - send: "你好，我想了解退款流程"
  - expect:
      intent: refund
  - send: "能给我具体步骤吗？"
  - assert:
      response_contains: ["退款", "步骤"]
```

✔ 非开发也能写
✔ 可版本化
✔ 可回归测试

---

# 四、核心模块设计（重点）

## 1️⃣ Test Orchestrator（最重要）

职责：

* 解析 scenario
* 创建 N 个虚拟用户
* 控制并发 / 速率
* 推进测试状态机

```python
class TestRun:
    id
    status: pending / running / done / failed
    progress: 0-100
```

---

## 2️⃣ Virtual User（模拟多用户）

每个虚拟用户是一个 **async task**：

```python
async def virtual_user(user_id, scenario):
    for step in scenario.steps:
        await step.execute()
        report_progress()
```

✔ 独立上下文（cookies / token / memory）
✔ 独立失败不影响全局

---

## 3️⃣ 实时状态 & 进度（你特别提到的）

### 推荐方案：WebSocket / SSE

```json
{
  "run_id": "xxx",
  "user_id": 12,
  "step": "send_message",
  "status": "success",
  "latency_ms": 842
}
```

前端可以画：

* 流程 DAG
* 用户泳道
* 热力图

---

## 4️⃣ 节点级状态（非常关键）

不要只存成功 / 失败
要存 **节点级事件**

```python
TestEvent:
  - timestamp
  - run_id
  - user_id
  - node: llm_call / tool_call / rag
  - status
  - latency
  - tokens
```

这会让你后期非常爽。

---

# 五、结果汇总 & 前端展示

## 1️⃣ 自动生成结果文件（你提到的）

### 推荐输出格式

* JSON（结构化）
* CSV（统计）
* HTML（可视化）

```json
{
  "run_id": "xxx",
  "summary": {
    "users": 50,
    "success_rate": 96.4,
    "avg_latency": 1.2
  },
  "failures": [...]
}
```

---

## 2️⃣ 前端核心视图建议

* ✅ 测试流程图（Step DAG）
* ✅ 实时进度条
* ✅ 用户并发曲线
* ✅ 节点失败分布
* ✅ Run 历史列表

---

# 六、与 Agent 项目的集成方式（重点）

### 不要直接 import Agent 代码

❌ 耦合太重
❌ 环境不一致

### 推荐方式

| 方式        | 说明          |
| --------- | ----------- |
| HTTP API  | 最推荐         |
| SDK       | 次选          |
| WebSocket | 实时对话型 Agent |

---

# 七、落地路线（一步一步，不要贪）

## Phase 1（1–2 周）

* FastAPI + uv
* 单 Scenario
* 10–20 并发用户
* JSON 结果输出

## Phase 2

* YAML 场景
* WebSocket 实时进度
* 节点级事件

## Phase 3

* 前端可视化
* 回归测试对比
* Token / 成本分析

---

# 八、一个非常重要的建议（经验之谈）

> **不要一开始就追求“全自动判断 Agent 是否正确”**

先做：

* 行为是否完成
* 是否走了正确工具
* 是否超时 / 失败

“正确性”后面再用规则 / LLM Judge。

---

# 九、如果你愿意，我可以继续帮你做

* 📁 项目目录结构（uv 版本）
* 🧠 Scenario DSL 设计
* 🧪 Virtual User 执行器代码
* 🔄 WebSocket 进度推送
* 📊 前端页面结构建议

你可以直接说一句：
👉 **“先帮我设计项目目录和核心数据模型”**
